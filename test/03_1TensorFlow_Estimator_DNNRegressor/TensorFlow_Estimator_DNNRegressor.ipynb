{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "731ffa18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:35:36.409937Z",
     "start_time": "2023-04-24T15:35:36.392785Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#基于Python TensorFlow Estimator DNNRegressor的深度学习回归\n",
    "#1 导入相关的库和包\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "import tensorflow as tf  #用最新的版本 2.11.0 在 #7时会报错，用2.4.1就没有报错了\n",
    "\n",
    "#基于TensorFlow的代码往往会输出较多的日志信息，从而使得我们对代码执行情况的了解受到一定影响。代码输出的日志信息有四种，\n",
    "#依据严重程度由低到高排序：INFO（通知）<WARNING（警告）<ERROR（错误）<FATAL（致命的）；\n",
    "#通过os.environ对TensorFlow的输出日志信息加以约束，“3”代表只输出FATAL信息。这句代码需放在 import tensorflow的前面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "981584ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:36:11.474080Z",
     "start_time": "2023-04-24T15:36:11.447993Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "#函数functions定义区\n",
    "import shutil\n",
    "#DeleteOldModel函数，删除上一次运行所保存的模型\n",
    "#需要注意，以下代码仅删除指定路径下的文件，文件夹不删除。大家如果需要将文件夹也同时删除，修改以上代码函数中的后面几句即可。\n",
    "def DeleteOldModel(ModelPath):\n",
    "    AllFileName=os.listdir(ModelPath) # 获取ModelPath路径下全部文件与文件夹\n",
    "    for i in AllFileName:\n",
    "        NewPath=os.path.join(ModelPath,i) # 分别将所获取的文件或文件夹名称与ModelPath路径组合\n",
    "        if os.path.isdir(NewPath): # 若组合后的新路径是一个文件夹\n",
    "            DeleteOldModel(NewPath) # 递归调用DeleteOldModel函数\n",
    "        else:\n",
    "            #os.chmod(NewPath,0o755)\n",
    "            os.remove(NewPath) # 若不是一个新的文件夹，而是一个文件，那么就删除\n",
    "            os.system('del '+NewPath)\n",
    "\n",
    "# LoadData函数，加载全部数据          \n",
    "def LoadData(DataPath):\n",
    "    MyData = pd.read_csv(DataPath, names=['Petrol_tax','Average_income','Paved_Highways','Population_Driver_licence',\n",
    "                                      'Petrol_Consumption'],header=0) #加载DataPath路径所指定的数据，names中的内容为各列的名称\n",
    "    return MyData\n",
    "\n",
    "# InputFun函数，训练数据与验证数据所用的Input函数\n",
    "def InputFun(Features,Labels,Training,BatchSize):\n",
    "    Datasets=tf.data.Dataset.from_tensor_slices((dict(Features),Labels)) # 对数据加以加载\n",
    "    if Training:\n",
    "        Datasets=Datasets.shuffle(1000).repeat() # 对于训练数据，需要打乱（shuffle）、重复（repeat）\n",
    "    return Datasets.batch(BatchSize) # 将经过上述处理后的数据以每次BatchSize个输出\n",
    "\n",
    "# InputFunPredict函数，测试数据所用的Input函数\n",
    "def InputFunPredict(Features,BatchSize):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(Features)).batch(BatchSize) # 对数据加以加载,以每次BatchSize个输出\n",
    "\n",
    "# AccuracyVerification函数，进行精度验证指标的计算与绘图\n",
    "def AccuracyVerification(PredictLabels,TestLabels):\n",
    "    value=0\n",
    "    PredictValuesList=[]\n",
    "    for k in PredictLabels:\n",
    "        value=k.get('predictions')[0]\n",
    "        PredictValuesList.append(value)\n",
    "    TestLabels=TestLabels.values.tolist()\n",
    "    TestYList=sum(TestLabels,[])\n",
    "    # 以上为获取测试数据的因变量与模型预测所得的因变量\n",
    "    Pearsonr=stats.pearsonr(TestYList,PredictValuesList) # 计算皮尔逊相关系数\n",
    "    R2=metrics.r2_score(TestYList,PredictValuesList) # 计算R方\n",
    "    RMSE=metrics.mean_squared_error(TestYList,PredictValuesList)**0.5 # 计算RMSE\n",
    "    plt.cla()\n",
    "    plt.plot(TestYList,PredictValuesList,'r*')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    # 以上为绘制拟合图像\n",
    "    print('Pearson correlation coefficient is {0}, and RMSE is {1}.'.format(Pearsonr[0],RMSE))\n",
    "    return (Pearsonr[0],R2,RMSE,PredictValuesList)\n",
    "\n",
    "# WriteAccuracy函数，将模型所涉及的参数与最终精度结果保存\n",
    "def WriteAccuracy(*WriteVar):\n",
    "    print(WriteVar)\n",
    "    ExcelData=openpyxl.load_workbook(WriteVar[0])\n",
    "    SheetName=ExcelData.get_sheet_names() # 获取全部Sheet\n",
    "    WriteSheet=ExcelData.get_sheet_by_name(SheetName[0]) # 获取指定Sheet\n",
    "    WriteSheet=ExcelData.active # 激活指定Sheet\n",
    "    MaxRowNum=WriteSheet.max_row # 获取指定Sheet对应第一个空行\n",
    "    for i in range(len(WriteVar)-1):\n",
    "        exec(\"WriteSheet.cell(MaxRowNum+1,i+1).value=WriteVar[i+1]\") # 用exec执行语句，写入信息\n",
    "    ExcelData.save(WriteVar[0]) # 保存文件'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "789ccd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:35:44.057960Z",
     "start_time": "2023-04-24T15:35:44.040518Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#2 参数配置\n",
    "#深度学习代码一大特点即为具有较多的参数需要我们手动定义。为避免调参时上下翻找，我们可以将主要的参数集中在一起，方便我们后期调整。\n",
    "#将各类变量放在一个位置集中定义，十分有利于机器学习等变量较多的代码\n",
    "\n",
    "MyDataPath=\"00_Data/AllDataAll.csv\" # 确定输入数据的位置\n",
    "MyModelPath=\"02_DNNModle/\" # 确定每一次训练所得模型保存的位置\n",
    "MyResultSavePath=\"03_OtherResult/EvalResult54.xlsx\" # 确定模型精度结果（RMSE等）与模型参数保存的位置\n",
    "\n",
    "TestSize=0.2 # 确定数据中测试集所占比例\n",
    "RandomSeed=np.random.randint(low=24,high=25) # 确定划分训练集与测试集的随机数种子\n",
    "OptMethod='Adam' # 确定模型所用的优化方法\n",
    "LearningRate=0.01 # 确定学习率\n",
    "DecayStep=200 # 确定学习率下降的步数\n",
    "DecayRate=0.96 # 确定学习率下降比率\n",
    "HiddenLayer=[64,128] # 确定隐藏层数量与每一层对应的神经元数量\n",
    "ActFun='tf.nn.relu' # 确定激活函数\n",
    "Dropout=0.3 # 确定Dropout的值\n",
    "LossReduction='tf.compat.v1.ReductionV2.SUM_OVER_BATCH_SIZE' # 指定每个批次训练误差的减小方法\n",
    "BatchNorm='False' # 确定是否使用Batch Normalizing\n",
    "TrainBatchSize=110 # 确定训练数据一个Batch的大小\n",
    "TrainStep=3000 # 确定训练数据的Step数量\n",
    "EvalBatchSize=1 # 确定验证数据一个Batch的大小\n",
    "PredictBatchSize=1 # 确定预测数据（即测试集）一个Batch的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46bf3408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:36:18.168433Z",
     "start_time": "2023-04-24T15:36:15.168199Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#3 原有模型删除\n",
    "#DNNRegressor每执行一次，便会在指定路径中保存当前运行的模型。\n",
    "#为保证下一次模型保存时不受上一次模型运行结果干扰，我们可以将模型文件夹内的全部文件删除。\n",
    "\n",
    "# 调用DeleteOldModel函数，删除上一次运行所保存的模型\n",
    "DeleteOldModel(MyModelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11f6bc35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:36:31.222270Z",
     "start_time": "2023-04-24T15:36:31.200497Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#4 数据导入与数据划分\n",
    "#初始数据集划分为训练集与测试集，数据训练集与测试集的划分在机器学习、深度学习中是不可或缺的作用\n",
    "#数据保存在csv文件中，因此可以用pd.read_csv直接读取。\n",
    "#其中，数据的每一列是一个特征，每一行是全部特征与因变量（就是下面的Yield）组合成的样本。\n",
    "    \n",
    "#初始数据处理\n",
    "AllXY = LoadData(MyDataPath) # 调用LoadData函数，获取数据\n",
    "#print(AllXY)\n",
    "Label={\"Petrol_Consumption\":AllXY.pop(\"Petrol_Consumption\")} # 将因变量从全部数据中提取出\n",
    "AllX,AllY=AllXY,(pd.DataFrame(Label)) # 将自变量与因变量分离\n",
    "#print(AllY)\n",
    "\n",
    "#划分数据训练集与测试集\n",
    "TrainX, TestX, TrainY,TestY= train_test_split(AllX,\n",
    "                                              AllY,\n",
    "                                              test_size=TestSize,  # 指定数据中测试集所占比例\n",
    "                                              random_state=RandomSeed) # 指定划分训练集与测试集的随机数种子\n",
    "#print(TestY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5c31797",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:36:32.976790Z",
     "start_time": "2023-04-24T15:36:32.959862Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#5 Feature Columns定义\n",
    "#Feature Columns就是一个桥梁，联系你的初始数据与模型；\n",
    "#其好比一个名单，模型拿着这个名单到你的数据（即#4部分你导入的数据）中按列的名称一一搜索，\n",
    "#若初始数据中的某列名称在Feature Columns里，那么模型就会把初始数据中这一列的数据全部拿到自己这里，进行训练。\n",
    "#因为我们是希望导入数据的全部特征，那么可以直接在全部数据的自变量中循环，将全部特征的名称导入Feature Columns。\n",
    "#在这里需要注意的是，只有连续数值变量才可以用tf.feature_column.numeric_column处理；若是类别变量可以参考：\n",
    "#https://blog.csdn.net/zhebushibiaoshifu/article/details/115335441。\n",
    "\n",
    "# estimator接口中的模型需要用“Feature columns”对象作为输入数据，只有这样模型才知道读取哪些数据\n",
    "FeatureColumn=[] # 定义一个新的“Feature columns”对象\n",
    "for key in AllX.keys():\n",
    "    FeatureColumn.append(tf.feature_column.numeric_column(key=key)) # 将全部因变量数据（需要均为连续变量）导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74767a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:36:34.852771Z",
     "start_time": "2023-04-24T15:36:34.839769Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '02_DNNModle/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#6 模型优化方法构建与模型结构构建\n",
    "#模型优化方法即模型中的optimizer，其可以在模型结构构建时输入；\n",
    "#但有时优化方法较为复杂（例如引入了学习率下降），那么在构建模型时配置优化方法的话就会有些不方便。因此我们首先构建模型优化方法。\n",
    "\n",
    "# 定义模型优化方法\n",
    "# Optimizer=OptMethod # 优化方法选用OptMethod所指定的方法  第一个\n",
    "# Optimizer=OptMethod # 优化方法选用OptMethod所指定的方法\n",
    "Optimizer=lambda:tf.keras.optimizers.Adam(\n",
    "    learning_rate=tf.compat.v1.train.exponential_decay(learning_rate=LearningRate, # 初始学习率\n",
    "                                                       global_step=tf.compat.v1.train.get_global_step(),\n",
    "                                                       # 全局步数，用以计算已经衰减后的学习率\n",
    "                                                       # get_global_step()函数自动获取当前的已经执行的步数\n",
    "                                                       decay_steps=DecayStep, # 学习率下降完成的指定步数\n",
    "                                                       decay_rate=DecayRate # 衰减率\n",
    "                                                       ) # 选用基于学习率指数下降的Adam方法，此举有助于降低过拟合风险\n",
    "                                                         # 这一函数返回每次对应的学习率\n",
    "    )\n",
    "\n",
    "#以上代码中有两个Optimizer=，第一个是直接输入优化方法的名称即可，名称包括：'Adagrad', 'Adam', 'Ftrl', 'RMSProp', SGD'；默认为Adagrad。\n",
    "#第二个是在选择了优化方法的基础上，配置其他信息。例如第二个，其代表着学习率指数下降的Adam优化方法。\n",
    "#其中，tf.compat.v1.train.exponential_decay可视作一个计算每次训练学习率的函数，他返回的是每一次对应的学习率。\n",
    "#可能这么说不太好理解，看这个公式：其返回值为 \n",
    "#   learning_rate *decay_rate^(global_step / decay_steps)，是不是就明白啦。\n",
    "#我们选择第二个优化方法，因此把第一个注释掉。\n",
    "\n",
    "#随后，我们定义模型的结构\n",
    "# 基于DNNRegressor构建深度学习模型\n",
    "DNNModel=tf.estimator.DNNRegressor(feature_columns=FeatureColumn, # 指定模型所用的“Feature columns”对象\n",
    "                                   hidden_units=HiddenLayer, # 指定隐藏层数量与每一层对应的神经元数量\n",
    "                                   optimizer=Optimizer, # 指定模型所用的优化方法\n",
    "                                   activation_fn=eval(ActFun), # 指定激活函数\n",
    "                                   dropout=Dropout,  # 指定Dropout的值\n",
    "                                   label_dimension=1, # 输出数据的维度，即因变量的个数\n",
    "                                   model_dir=MyModelPath, # 指定每一次训练所得模型保存的位置\n",
    "                                   #loss_reduction=eval(LossReduction), # 指定每个批次训练误差的减小方法\n",
    "                                   batch_norm=eval(BatchNorm) # 指定是否使用Batch Normalizing\n",
    "                                  )\n",
    "\n",
    "#其中，我把loss_reduction注释掉，是因为可能由于TensorFlow版本的问题，其总是报错，所以就用默认的值就好；\n",
    "#而最后一个batch_norm，决定了是否进行Batch Normalizing。\n",
    "#Batch Normalizing可以保持深度神经网络在每一层保持相同分布，从而加快网络收敛与增强网络稳固性。\n",
    "#其它参数可以参考：\n",
    "#https://www.tensorflow.org/api_docs/python/tf/estimator/DNNRegressor；\n",
    "#https://www.tensorflow.org/api_docs/python/tf/nn\n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO) # 将INFO级别的日志信息显示到屏幕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d950a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:36:50.262263Z",
     "start_time": "2023-04-24T15:36:44.216276Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into 02_DNNModle/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 3223591.5, step = 0\n",
      "INFO:tensorflow:global_step/sec: 530.326\n",
      "INFO:tensorflow:loss = 39270.71, step = 100 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.676\n",
      "INFO:tensorflow:loss = 26762.889, step = 200 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.935\n",
      "INFO:tensorflow:loss = 29559.348, step = 300 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.672\n",
      "INFO:tensorflow:loss = 25932.375, step = 400 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.655\n",
      "INFO:tensorflow:loss = 21757.336, step = 500 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.655\n",
      "INFO:tensorflow:loss = 22561.281, step = 600 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.932\n",
      "INFO:tensorflow:loss = 20562.307, step = 700 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.677\n",
      "INFO:tensorflow:loss = 20054.95, step = 800 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.931\n",
      "INFO:tensorflow:loss = 16678.096, step = 900 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.232\n",
      "INFO:tensorflow:loss = 22663.266, step = 1000 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.705\n",
      "INFO:tensorflow:loss = 21566.445, step = 1100 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.596\n",
      "INFO:tensorflow:loss = 27718.693, step = 1200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.574\n",
      "INFO:tensorflow:loss = 20905.057, step = 1300 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.874\n",
      "INFO:tensorflow:loss = 16526.402, step = 1400 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.186\n",
      "INFO:tensorflow:loss = 20999.76, step = 1500 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.676\n",
      "INFO:tensorflow:loss = 19114.078, step = 1600 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.932\n",
      "INFO:tensorflow:loss = 21926.762, step = 1700 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.659\n",
      "INFO:tensorflow:loss = 20014.82, step = 1800 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.139\n",
      "INFO:tensorflow:loss = 19532.172, step = 1900 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.272\n",
      "INFO:tensorflow:loss = 19176.23, step = 2000 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.272\n",
      "INFO:tensorflow:loss = 19145.861, step = 2100 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.67\n",
      "INFO:tensorflow:loss = 19898.037, step = 2200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.664\n",
      "INFO:tensorflow:loss = 18839.344, step = 2300 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.665\n",
      "INFO:tensorflow:loss = 21714.893, step = 2400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 666.669\n",
      "INFO:tensorflow:loss = 22011.078, step = 2500 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.931\n",
      "INFO:tensorflow:loss = 20648.982, step = 2600 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.272\n",
      "INFO:tensorflow:loss = 24731.537, step = 2700 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.677\n",
      "INFO:tensorflow:loss = 26052.262, step = 2800 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.595\n",
      "INFO:tensorflow:loss = 20193.389, step = 2900 (0.153 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3000...\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into 02_DNNModle/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3000...\n",
      "INFO:tensorflow:Loss for final step: 18686.55.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNRegressorV2 at 0x1e66dbed748>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7 模型训练\n",
    "#训练模型这一部分，我认为反而比模型的构建可能还难理解一些。我们先看代码\n",
    "# 基于训练数据训练模型\n",
    "DNNModel.train(input_fn=lambda:InputFun(TrainX, TrainY,True,TrainBatchSize),#调用InputFun函数；InputFun函数返回“tf.data.Dataset”对象，这个对象才可以被train函数识别并带入模型；由于InputFun函数每次返回BatchSize大小的数据个数，因此需要多次执行，前面需要加lambda              \n",
    "               steps=TrainStep) # 指定模型训练的步数\n",
    "    \n",
    "#那我们首先就看input function——也就是代码中的InputFun函数。其实这个函数的用处很简单，用官网的话说，\n",
    "#其就是用来输入模型支持的数据类型的——只有经过input function处理后，数据才可以被DNNRegressor识别。\n",
    "#听上去这么厉害，它到底是如何操作的呢？\n",
    "#很简单，它只需要将初始的数据转换为特定的格式即可，这个格式是一个元组（tuple），这个元组有两个元素：\n",
    "#一就是features，是一个字典。这个字典的每一个键是每一个特征的名称，\n",
    "#就比如用植物特性对花的种类加以区分，那么花的“叶长”“叶片厚度”等等就是一个个特征的名称，也就是这里的一个个“键”；\n",
    "#而这个字典的值，就是这个特征对应的全部样本的数值组成的数组。\n",
    "#二就是label，是全部样本对应的label，也就是因变量。\n",
    "#不知道大家有没有理解，我们就举一个简单的例子。\n",
    "#假如我们用两个地方的温度与降水预测这两个地方的作物产量：其温度分别为10 ℃、20 ℃，降水分别为15 mm，25 mm，\n",
    "#作物产量分别为100千克每公顷，150千克每公顷——那么tuple由两个部分组成：\n",
    "#tuple=(features,label)\n",
    "#features={'温度':np.array([10,20]),'降水':np.array([15,25])}\n",
    "#label=np.array([100,150])\n",
    "#tuple=(features,label)\n",
    "#print(tuple)\n",
    "#理解了之后，我们继续看InputFun函数。\n",
    "#首先，tf.data.Dataset.from_tensor_slices用来将输入的数据加载并转换为Datase的形式；\n",
    "#随后，如果是训练状态下，那么数据会进行打乱.shuffle(1000)——相当于对数据加以洗牌，防止初始数据具有一定的趋势。\n",
    "#例如如果我们做分类，其中初始数据的前80%都是第一类，后20%都是第二类，\n",
    "#那么如果我们不打乱数据，会使得用前80%数据训练出来的结果都是第一类（即模型只认识第一类），\n",
    "#在后20%进行测试时，所得结果也全都为第一类；所以要打乱。\n",
    "#其中的1000是buffer_size参数，这个数据必须要比你的数据样本个数大。至于.shuffle(1000)这个函数的原理我一直没有搞明白，大家感兴趣的话可以了解一下：\n",
    "#https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle。\n",
    "#.repeat()则是对数据集加以重复，之所以要重复，是因为我们需要对全部数据训练好几轮（即好几个Epoch），因此要对初始数据加以重复。\n",
    "#随后，用.batch()函数输出BatchSize个数据，也就是一批数据；其中BatchSize就是每一批数据的个数。\n",
    "#以上就是InputFun函数。\n",
    "#可以这么理解：在train函数中，只有一个参数input_fn；\n",
    "#而这个参数的输入，又是一个新的函数——这个新的函数就是大名鼎鼎的input function了,参考上面。\n",
    "#再看train函数：大家也看出来了，这个InputFun函数是每次输出一批（BatchSize个）数据；\n",
    "#而我们训练的时候，肯定是要一批一批不停输入数据的，因此这就解释了为什么InputFun函数前有一个lambda——因为InputFun函数\n",
    "#要把处理后的数据分多次传给train。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14555c9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:36:57.415721Z",
     "start_time": "2023-04-24T15:36:56.856000Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2023-04-24T23:36:57Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from 02_DNNModle/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.16627s\n",
      "INFO:tensorflow:Finished evaluation at 2023-04-24-23:36:57\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 38421.21, global_step = 3000, label/mean = 581.3, loss = 38421.21, prediction/mean = 411.33267\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: 02_DNNModle/model.ckpt-3000\n",
      "ev:{'average_loss': 38421.21, 'label/mean': 581.3, 'loss': 38421.21, 'prediction/mean': 411.33267, 'global_step': 3000}\n"
     ]
    }
   ],
   "source": [
    "#8 模型试验证明与测试\n",
    "#理解了上面的内容，接下来就很好理解了。\n",
    "#我们需要进行实验证明和测试的操作——其他实验证明也是利用了测试收集数据，\n",
    "#所以我还希望可以获得测试集预测结果，从更直观地了解了模型精度水平。\n",
    "\n",
    "#验证模型并保存验证结果\n",
    "EvalResult = DNNModel.evaluate(input_fn=lambda:InputFun(TestX,TestY,False,EvalBatchSize))\n",
    "\n",
    "#打印验证结果\n",
    "print('ev:{}'.format(EvalResult))\n",
    "\n",
    "#基于测试数据测试模型精度结果\n",
    "PredictValues=DNNModel.predict(input_fn=lambda:InputFunPredict(TestX,PredictBatchSize))\n",
    "\n",
    "#其中，验证时.evaluate所用的InputFun函数其实和训练集所用的是一样的函数，\n",
    "#只是验证时不需要进行打乱.shuffle(1000)和重新.repeat()操作；\n",
    "#而测试时.predict的InputFun函数，是印要输入自变量、无需输入因变化量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84616eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:37:00.901137Z",
     "start_time": "2023-04-24T15:37:00.496702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from 02_DNNModle/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Pearson correlation coefficient is -0.2757528162810703, and RMSE is 196.0132943388858.\n",
      "('03_OtherResult/EvalResult54.xlsx', -0.2757528162810703, -5.640822930958476, 196.0132943388858, 0.2, 24, 'Adam', 0.01, 200, 0.96, '64,128', 'tf.nn.relu', 0.3, 'tf.compat.v1.ReductionV2.SUM_OVER_BATCH_SIZE', 'False', 110, 3000, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda\\envs\\cudaOCRpy37\\lib\\site-packages\\ipykernel_launcher.py:58: DeprecationWarning: Call to deprecated function get_sheet_names (Use wb.sheetnames).\n",
      "D:\\Miniconda\\envs\\cudaOCRpy37\\lib\\site-packages\\ipykernel_launcher.py:59: DeprecationWarning: Call to deprecated function get_sheet_by_name (Use wb[sheetname]).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9u0lEQVR4nO3deViVdf7/8ddBlkQ8ECIeTdRcUlDUkMmwb+mIOzVWzFSGicaoObhWjtGvVTNNa9KuFqspd9NsccpGjdxLBnGhzDG3UaEU0UwWFxS4f38QJ09qnYMHDtw+H9d1rpvz+dznvt/33Qlefu7NYhiGIQAAAJPy8nQBAAAAlYmwAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATM3b0wVUB6WlpTp8+LDq1q0ri8Xi6XIAAIATDMNQQUGBGjVqJC+vy4/fEHYkHT58WGFhYZ4uAwAAVEB2drYaN2582X7CjqS6detKKttZVqvVw9UAAABn5OfnKywszP53/HIIO5L90JXVaiXsAABQw/zeKSicoAwAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsAMAAEyNsFOZtmyRuncvmwIAAI8g7FSmefOktWul+fM9XQkAAFctHgTqbocOScePSxaLtGRJWdvixVJiomQYUkiI1LSpZ2sEAOAqQthxt2bNfvm5/Cmsx45JnTr90m4YVVoSAABXMw5juduCBZL3zxmyPNSUT729y/oBAECVYWTH3RISpPBwx5GccunpUlRU1dcEAMBVjJGdyuTl5TgFAABVjr/ClSE0VLLZykZ3Zs0qm9psZe0AAKBKcRirMjRuLB08KPn6lp2kPGyYdO6c5Ofn6coAALjqEHYqy4XBxmIh6AAA4CEcxgIAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZG2AEAAKZWbcLO1KlTZbFYNHbsWIf2tLQ0de/eXXXq1JHVatVtt92mM2fO2PtPnDihhIQEWa1WBQUFKSkpSYWFhVVcPQAAqK6qRdjJyMjQm2++qfbt2zu0p6WlqU+fPurVq5c2b96sjIwMjRw5Ul5ev5SdkJCgnTt3KjU1VcuXL9eGDRs0bNiwqt4EAABQTVkMwzA8WUBhYaGioqL0+uuv67nnnlPHjh01Y8YMSdLNN9+snj17atKkSZf87K5duxQREaGMjAxFR0dLklauXKl+/frp+++/V6NGjZyqIT8/X4GBgcrLy5PVanXLdgEAgMrl7N9vj4/sJCcnKy4uTj169HBoz83NVXp6ukJDQ9WlSxc1aNBAXbt21ZdffmmfJy0tTUFBQfagI0k9evSQl5eX0tPTL7vOoqIi5efnO7wAAIA5eTTsLF68WNu2bdOUKVMu6vvf//4nSXrmmWc0dOhQrVy5UlFRUYqNjdXevXslSTk5OQoNDXX4nLe3t4KDg5WTk3PZ9U6ZMkWBgYH2V1hYmBu3CgAAVCceCzvZ2dkaM2aMFi5cqGuuueai/tLSUknS8OHDNWTIEN144416+eWX1bp1a7377rtXtO6UlBTl5eXZX9nZ2Ve0PAAAUH15e2rFW7duVW5urqKiouxtJSUl2rBhg1599VXt3r1bkhQREeHwufDwcGVlZUmSbDabcnNzHfqLi4t14sQJ2Wy2y67bz89Pfn5+7toUAABQjXlsZCc2NlY7duxQZmam/RUdHa2EhARlZmaqefPmatSokT30lNuzZ4+aNm0qSYqJidHJkye1detWe/+aNWtUWlqqzp07V+n2AACA6sljIzt169ZVu3btHNrq1KmjevXq2dvHjx+vp59+Wh06dFDHjh01d+5cfffdd/rggw8klY3y9OnTR0OHDtWsWbN0/vx5jRw5Uvfdd5/TV2IBAABz81jYccbYsWN19uxZjRs3TidOnFCHDh2UmpqqFi1a2OdZuHChRo4cqdjYWHl5eSk+Pl6vvPKKB6sGAADVicfvs1MdcJ8dAABqnhpznx0AAOy2bJG6dy+bAm5C2AEAVB/z5klr10rz53u6EphItT5nBwBwFTh0SDp+XLJYpCVLytoWL5YSEyXDkEJCpJ+vwgUqgrADAPCsZs1++dliKZseOyZ16vRLO6eX4gpwGAsA4FkLFkjeP//buzzUlE+9vcv6gSvAyA4AwLMSEqTwcMeRnHLp6dIFd9oHKoKRHQBA9eHl5TgF3IBvEwDA80JDJZutbHRn1qyyqc1W1g5cIQ5jAQA8r3Fj6eBByde37CTlYcOkc+ckHtoMNyDsAACqhwuDjcVC0IHbcBgLAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHAACYGmEHqE62bJG6dy+bAgDcgrADVCfz5klr10rz53u6EgAwDZ56DnjaoUPS8eNlT3lesqSsbfFiKTFRMgwpJERq2tSzNQJADUbYATytWbNffrZYyqbHjkmdOv3SbhhVWhJQI23ZIv3979K0aVJ0tKerQTXCYSzA0xYskLx//ndHeagpn3p7l/UD+H0cBsZlMLIDeFpCghQe7jiSUy49XYqKqvqagJqCw8BwAmEHqE68vKTS0l+mAH4bh4HhBA5jAdVBaKhks5X9gp41q2xqs5W1A7g8DgPDCRbDIPLm5+crMDBQeXl5slqtni4HV6uiIsnXt+xfp4YhnTsn+fl5uiqg+tu27dKHgbdu5TCwyTn795uRHaC68PP7ZRjeYiHoAK7y8nKcAj/jGwEAqNk4DIzfwQnKAICarXFj6eDBXw4DDxvGYWA4IOwAAGq+C4MNh4HxKxzGAgAApkbYAQAApkbYAQAApkbYAQAApkbYAQAAplZtws7UqVNlsVg0duzYi/oMw1Dfvn1lsVi0bNkyh76srCzFxcXJ399foaGhGj9+vIqLi6umaAAAUO1Vi0vPMzIy9Oabb6p9+/aX7J8xY4Ys5XeWvUBJSYni4uJks9m0adMmHTlyRIMGDZKPj4+ef/75yi4bAADUAB4f2SksLFRCQoLefvttXXvttRf1Z2Zm6qWXXtK77757Ud/nn3+u//73v1qwYIE6duyovn37atKkSXrttdd07ty5qigfAABUcx4PO8nJyYqLi1OPHj0u6jt9+rTuv/9+vfbaa7LZbBf1p6WlKTIyUg0aNLC39e7dW/n5+dq5c+dl11lUVKT8/HyHFwAAMCePHsZavHixtm3bpoyMjEv2jxs3Tl26dFH//v0v2Z+Tk+MQdCTZ3+fk5Fx2vVOmTNGzzz5bwaoBAEBN4rGwk52drTFjxig1NVXXXHPNRf2ffPKJ1qxZo+3bt7t93SkpKXr44Yft7/Pz8xUWFub29QAAAM/z2GGsrVu3Kjc3V1FRUfL29pa3t7fWr1+vV155Rd7e3kpNTdX+/fsVFBRk75ek+Ph4devWTZJks9l09OhRh+WWv7/UYa9yfn5+slqtDi8AAGBOHhvZiY2N1Y4dOxzahgwZojZt2mjChAkKCQnR8OHDHfojIyP18ssv64477pAkxcTEaPLkycrNzVVoaKgkKTU1VVarVREREVWzIQAAoFrzWNipW7eu2rVr59BWp04d1atXz95+qdGZJk2a6Prrr5ck9erVSxEREXrggQc0bdo05eTk6IknnlBycrL8eOItAABQNbga60rUqlVLy5cvV61atRQTE6OBAwdq0KBBmjhxoqdLAwAA1YTFMAzD00V4Wn5+vgIDA5WXl8f5OwAA1BDO/v2u0SM7AAAAv4ewAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wAwAATI2wU91s2SJ17142BQAAV4ywU93MmyetXSvNn+/pSgAAMAWPPfUcFzh0SDp+XLJYpCVLytoWL5YSEyXDkEJCpKZNPVsjAAA1FGGnOmjW7JefLZay6bFjUqdOv7TzvFYAACqEw1jVwYIFkvfPubM81JRPvb3L+gEAQIUwslMdJCRI4eGOIznl0tOlqKiqrwkAAJNgZKe68fJynAIAgCvCX9TqIjRUstnKRndmzSqb2mxl7QAAoMI4jFVdNG4sHTwo+fqWnaQ8bJh07pzk5+fpygAAqNEIO9XJhcHGYiHoAADgBhzGAgAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApkbYAQAApnbFYSc/P1/Lli3Trl273FEPAACAW7kcdu655x69+uqrkqQzZ84oOjpa99xzj9q3b68PP/zQ7QUCAABcCZfDzoYNG3TrrbdKkj7++GMZhqGTJ0/qlVde0XPPPef2AgEAAK6Ey2EnLy9PwcHBkqSVK1cqPj5e/v7+iouL0969e91eIAAAwJVwOeyEhYUpLS1Np06d0sqVK9WrVy9J0k8//aRrrrnG7QUCAABcCZcfBDp27FglJCQoICBATZo0Ubdu3SSVHd6KjIx0d30AAABXxOWw87e//U033XSTsrOz1bNnT3l5lQ0ONW/enHN2AABAtWMxDMOoyAfPnTunAwcOqEWLFvL2djkzVSv5+fkKDAxUXl6erFarp8sBAABOcPbvt8vn7Jw+fVpJSUny9/dX27ZtlZWVJUkaNWqUpk6dWvGKAQAAKoHLYSclJUVff/211q1b53BCco8ePbRkyRK3FgcAAHClXD7+tGzZMi1ZskQ333yzLBaLvb1t27bav3+/W4sDAAC4Ui6P7Bw7dkyhoaEXtZ86dcoh/AAAAFQHLoed6OhoffbZZ/b35QHnn//8p2JiYtxXGQAAgBu4HHaef/55Pf744xoxYoSKi4s1c+ZM9erVS7Nnz9bkyZMrXMjUqVNlsVg0duxYSdKJEyc0atQotW7dWrVr11aTJk00evRo5eXlOXwuKytLcXFx8vf3V2hoqMaPH6/i4uIK1wEAAMzF5bDzf//3f8rMzFRxcbEiIyP1+eefKzQ0VGlpaerUqVOFisjIyNCbb76p9u3b29sOHz6sw4cP68UXX9S3336rOXPmaOXKlUpKSrLPU1JSori4OJ07d06bNm3S3LlzNWfOHD311FMVqgMAAJhPhe+z4y6FhYWKiorS66+/rueee04dO3bUjBkzLjnv0qVLNXDgQJ06dUre3t5asWKFbr/9dh0+fFgNGjSQJM2aNUsTJkzQsWPH5Ovr61QN3GcHAICap9Lus5OVlfWbL1clJycrLi5OPXr0+N15yzem/CaGaWlpioyMtAcdSerdu7fy8/O1c+fOyy6nqKhI+fn5Di8AAGBOLl963qxZs9+86qqkpMTpZS1evFjbtm1TRkbG7857/PhxTZo0ScOGDbO35eTkOAQdSfb3OTk5l13WlClT9OyzzzpdJwAAqLlcDjvbt293eH/+/Hlt375d//jHP1w6QTk7O1tjxoxRamrq7z4tPT8/X3FxcYqIiNAzzzzjaskXSUlJ0cMPP+yw/LCwsCteLgAAqH5cDjsdOnS4qC06OlqNGjXS9OnTdffddzu1nK1btyo3N1dRUVH2tpKSEm3YsEGvvvqqioqKVKtWLRUUFKhPnz6qW7euPv74Y/n4+Njnt9ls2rx5s8Nyjx49au+7HD8/P/n5+TlVJwAAqNlcPmfnclq3bu3U4ahysbGx2rFjhzIzM+2v6OhoJSQkKDMzU7Vq1VJ+fr569eolX19fffLJJxeNAMXExGjHjh3Kzc21t6WmpspqtSoiIsJdmwYAAGowl0d2fn0yr2EYOnLkiJ555hm1atXK6eXUrVtX7dq1c2irU6eO6tWrp3bt2tmDzunTp7VgwQKHE4nr16+vWrVqqVevXoqIiNADDzygadOmKScnR0888YSSk5MZuQEAAJIqEHaCgoIuOkHZMAyFhYVp8eLFbits27ZtSk9PlyS1bNnSoe/AgQNq1qyZatWqpeXLl2vEiBGKiYlRnTp1lJiYqIkTJ7qtDgAAULO5fJ+d9evXO7z38vJS/fr11bJlS/sl4TUN99kBAKDmcfbvt8vppGvXrldUGAAAQFVyKux88sknTi/wT3/6U4WLAQAAcDenws6dd97p1MIsFotLNxUEAACobE6FndLS0squAwAAoFK47T47AAAA1VGFLp86deqU1q9fr6ysLJ07d86hb/To0W4pDAAAwB0q9Gysfv366fTp0zp16pSCg4N1/Phx+fv7KzQ0lLADAACqFZcPY40bN0533HGHfvrpJ9WuXVv/+c9/dOjQIXXq1EkvvvhiZdQIAABQYS6HnczMTD3yyCPy8vJSrVq1VFRUpLCwME2bNk2PP/54ZdQIAABQYS6HHR8fH3l5lX0sNDRUWVlZkqTAwEBlZ2e7tzoAAIAr5PI5OzfeeKMyMjLUqlUrde3aVU899ZSOHz+u+fPnX/RgTwAAAE9zemSn/GaBzz//vBo2bChJmjx5sq699lqNGDFCx44d01tvvVU5VQIAAFSQ0yM71113nQYPHqwHH3xQ0dHRksoOY61cubLSigMAALhSTo/sJCcn64MPPlB4eLhuvfVWzZkzR6dPn67M2gAAAK6Y02HnySef1L59+7R69Wo1b95cI0eOVMOGDTV06FClp6dXZo0AAAAV5vLVWN26ddPcuXOVk5Ojl156Sbt27VJMTIzatm2rf/zjH5VRIwAAQIVZDMMwrnQhn332mQYNGqSTJ0/WyKee5+fnKzAwUHl5ebJarZ4uBwAAOMHZv98VfhDo6dOnNWfOHHXt2lV/+tOfVK9ePU2ePLmiiwMAAKgULt9nZ9OmTXr33Xe1dOlSFRcX689//rMmTZqk2267rTLqAwAAuCJOh51p06Zp9uzZ2rNnj6KjozV9+nQNGDBAdevWrcz6AAAArojTYWf69OkaOHCgli5dyp2SAQBAjeF02Dl8+LB8fHwqsxYAAAC3c/oEZYIOAACoiSp8NRYAAEBNQNgBAACmRtgBAACm5tQJyvn5+U4vkDsQAwCA6sSpsBMUFCSLxeLUAmvi4yIAwKO2bJH+/ndp2jQpOtrT1QCm41TYWbt2rf3ngwcP6rHHHtPgwYMVExMjSUpLS9PcuXM1ZcqUyqkSAMxs3jxp7Vpp/nzCDlAJXH4QaGxsrP76179qwIABDu2LFi3SW2+9pXXr1rmzvirBg0ABVLlDh6TjxyWLRerbV8rNlUJDpRUrJMOQQkKkpk09XSVQrTn799vlsOPv76+vv/5arVq1cmjfs2ePOnbsqNOnT1esYg8i7ACocheeGmCxlAWc8mk51349A1edSnvqeVhYmN5+++2L2v/5z38qLCzM1cUBwNVpwQLJ++czCcpDTfnU27usH4BbuPzU85dfflnx8fFasWKFOnfuLEnavHmz9u7dqw8//NDtBQKAKSUkSOHhUqdOF/elp0tRUVVfE2BSLo/s9OvXT3v27NEdd9yhEydO6MSJE7rjjju0Z88e9evXrzJqBABz8/JynAJwK5dHdqSyQ1nPP/+8u2sBgKtLaKhks0lhYVJSkvTOO1J2dlk7ALep0D8jNm7cqIEDB6pLly764YcfJEnz58/Xl19+6dbiAMDUGjeWDh4sO2w1fHjZ9ODBsnYAbuNy2Pnwww/Vu3dv1a5dW9u2bVNRUZEkKS8vj9EeAHCVn98vV2ZZLGXvAbiVy2Hnueee06xZs/T222/Lx8fH3n7LLbdo27Ztbi0OAADgSrkcdnbv3q3bbrvtovbAwECdPHnSHTUBAAC4jcthx2azad++fRe1f/nll2revLlbigIAAHAXl8PO0KFDNWbMGKWnp8tisejw4cNauHChHn30UY0YMaLChUydOlUWi0Vjx461t509e1bJycmqV6+eAgICFB8fr6NHjzp8LisrS3FxcfL391doaKjGjx+v4uLiCtcBAADMxeVLzx977DGVlpYqNjZWp0+f1m233SY/Pz89+uijGjVqVIWKyMjI0Jtvvqn27ds7tI8bN06fffaZli5dqsDAQI0cOVJ33323vvrqK0llT1iPi4uTzWbTpk2bdOTIEQ0aNEg+Pj6cLA0AACRV4NlY5c6dO6d9+/apsLBQERERCggIqFABhYWFioqK0uuvv67nnntOHTt21IwZM5SXl6f69etr0aJF+vOf/yxJ+u677xQeHq60tDTdfPPNWrFihW6//XYdPnxYDRo0kCTNmjVLEyZM0LFjx+Tr63vJdRYVFdmvIpPKnq0RFhbGs7EAAKhBKu3ZWA8++KAKCgrk6+uriIgI3XTTTQoICNCpU6f04IMPulxocnKy4uLi1KNHD4f2rVu36vz58w7tbdq0UZMmTZSWliZJSktLU2RkpD3oSFLv3r2Vn5+vnTt3XnadU6ZMUWBgoP3FM70AADAvl8PO3LlzdebMmYvaz5w5o3nz5rm0rMWLF2vbtm2aMmXKRX05OTny9fVVUFCQQ3uDBg2Uk5Njn+fCoFPeX953OSkpKcrLy7O/srOzXaobAADUHE6fs5Ofny/DMGQYhgoKCnTNNdfY+0pKSvTvf/9boS7c4jw7O1tjxoxRamqqw7Kqgp+fn/y4cRcAAFcFp8NOUFCQLBaLLBaLbrjhhov6LRaLnn32WadXvHXrVuXm5irqgif7lpSUaMOGDXr11Ve1atUqnTt3TidPnnQY3Tl69KhsNpukssvgN2/e7LDc8qu1yucBAABXN6fDztq1a2UYhrp3764PP/xQwcHB9j5fX181bdpUjRo1cnrFsbGx2rFjh0PbkCFD1KZNG02YMEFhYWHy8fHR6tWrFR8fL6nshoZZWVmKiYmRJMXExGjy5MnKzc21jyqlpqbKarUqIiLC6VoAAIB5OR12unbtKkk6cOCAmjRpIkv5s1wqqG7dumrXrp1DW506dVSvXj17e1JSkh5++GEFBwfLarVq1KhRiomJ0c033yxJ6tWrlyIiIvTAAw9o2rRpysnJ0RNPPKHk5GQOUwEAAEkVuM/OmjVrFBAQoL/85S8O7UuXLtXp06eVmJjotuJefvlleXl5KT4+XkVFRerdu7def/11e3+tWrW0fPlyjRgxQjExMapTp44SExM1ceJEt9UAAABqNpfvs3PDDTfozTff1B//+EeH9vXr12vYsGHavXu3WwusCs5epw8AAKqPSrvPTlZWlq6//vqL2ps2baqsrCxXFwcAAFCpXA47oaGh+uabby5q//rrr1WvXj23FAUAAExiyxape/eyqYe4HHYGDBig0aNHa+3atSopKVFJSYnWrFmjMWPG6L777quMGgEAQE01b560dq00f77HSnD5BOVJkybp4MGDio2Nlbd32cdLS0s1aNAgHr4JAACkQ4ek48cli0VasqSsbfFiKTFRMgwpJERq2rTKyqnwg0D37Nmjr7/+WrVr11ZkZKSaVmHR7sYJygAAuNGFt6exWMoCTvm0XMXihwNn/367PLJT7oYbbrjknZQBAMBVbsECafBgqbj4l1BTPvX2lubMqdJynAo7Dz/8sCZNmqQ6dero4Ycf/s15//GPf7ilMAAAUEMlJEjh4VKnThf3padLFzwqqio4FXa2b9+u8+fP23++nCu9qzIAADAZLy+ptPSXqQc4FXbWrl17yZ8BAAAuKTRUstmksDApKUl65x0pO7usvYpV+JwdAACAy2rcWDp4UPL1LTs5edgw6dw5yQPPrnQq7Nx9991OL/Cjjz6qcDEAAMBELgw2FotHgo7k5E0FAwMD7S+r1arVq1drywV3Qty6datWr16twMDASisUAACgIpwa2Zk9e7b95wkTJuiee+7RrFmzVKtWLUlSSUmJ/va3v3GPGgAAUO24fFPB+vXr68svv1Tr1q0d2nfv3q0uXbroxx9/dGuBVYGbCgIAUPNU2lPPi4uL9d13313U/t1336nUQ5eUAQAAXI7LV2MNGTJESUlJ2r9/v2666SZJUnp6uqZOnaohQ4a4vUAAAIAr4XLYefHFF2Wz2fTSSy/pyJEjkqSGDRtq/PjxeuSRR9xeIAAAwJWo8INApbJjZZJq/HkunLMDAEDNU2nn7Ehl5+188cUXeu+99+yPiDh8+LAKCwsrVi0AAEAlcfkw1qFDh9SnTx9lZWWpqKhIPXv2VN26dfXCCy+oqKhIs2bNqow6AQAAKsTlkZ0xY8YoOjpaP/30k2rXrm1vv+uuu7R69Wq3FgcAAHClXB7Z2bhxozZt2iRfX1+H9mbNmumHH35wW2EAAADu4PLITmlpqUpKSi5q//7771W3bl23FAUAAOAuLoedXr16acaMGfb3FotFhYWFevrpp9WvXz931gYAAHDFXL70PDs7W3369JFhGNq7d6+io6O1d+9ehYSEaMOGDQoNDa2sWisNl54DAFDzOPv3u0L32SkuLtaSJUv09ddfq7CwUFFRUUpISHA4YbkmIewAAFDzVErYOX/+vNq0aaPly5crPDzcLYVWB4QdAABqnkq5qaCPj4/Onj17xcUBAABUFZdPUE5OTtYLL7yg4uLiyqgHAADArVy+z05GRoZWr16tzz//XJGRkapTp45D/0cffeS24gAAAK6Uy2EnKChI8fHxlVELAACA27kcdmbPnl0ZdQAAAFQKp8/ZKS0t1QsvvKBbbrlFf/jDH/TYY4/pzJkzlVkbAADAFXM67EyePFmPP/64AgICdN1112nmzJlKTk6uzNoAAACumNNhZ968eXr99de1atUqLVu2TJ9++qkWLlyo0tLSyqwPAADgijgddrKyshyefdWjRw9ZLBYdPny4UgoDAABwB6fDTnFxsa655hqHNh8fH50/f97tRQEAALiL01djGYahwYMHy8/Pz9529uxZPfTQQw732uE+OwAAoDpxOuwkJiZe1DZw4EC3FgMAAOBuToedyri/zhtvvKE33nhDBw8elCS1bdtWTz31lPr27StJysnJ0fjx45WamqqCggK1bt1a/+///T+HmxqeOHFCo0aN0qeffiovLy/Fx8dr5syZCggIcHu9AACg5nH52Vju1LhxY02dOlVbt27Vli1b1L17d/Xv3187d+6UJA0aNEi7d+/WJ598oh07dujuu+/WPffco+3bt9uXkZCQoJ07dyo1NVXLly/Xhg0bNGzYME9tEgAAqGYshmEYni7iQsHBwZo+fbqSkpIUEBCgN954Qw888IC9v169enrhhRf017/+Vbt27VJERIQyMjIUHR0tSVq5cqX69eun77//Xo0aNbrkOoqKilRUVGR/n5+fr7CwsN99RDwAAKg+8vPzFRgY+Lt/vz06snOhkpISLV68WKdOnVJMTIwkqUuXLlqyZIlOnDih0tJSLV68WGfPnlW3bt0kSWlpaQoKCrIHHanskngvLy+lp6dfdl1TpkxRYGCg/RUWFlap2wYAADzH42Fnx44dCggIkJ+fnx566CF9/PHHioiIkCS9//77On/+vOrVqyc/Pz8NHz5cH3/8sVq2bCmp7Jye0NBQh+V5e3srODhYOTk5l11nSkqK8vLy7K/s7OzK20AAAOBRLj8I1N1at26tzMxM5eXl6YMPPlBiYqLWr1+viIgIPfnkkzp58qS++OILhYSEaNmyZbrnnnu0ceNGRUZGVnidfn5+DpfQAwAA8/J42PH19bWP1HTq1EkZGRmaOXOm/v73v+vVV1/Vt99+q7Zt20qSOnTooI0bN+q1117TrFmzZLPZlJub67C84uJinThxQjabrcq3BQAAVD8eP4z1a6WlpSoqKtLp06clSV5ejiXWqlXL/jyumJgYnTx5Ulu3brX3r1mzRqWlpercuXPVFQ0AAKotj47spKSkqG/fvmrSpIkKCgq0aNEirVu3TqtWrVKbNm3UsmVLDR8+XC+++KLq1aunZcuW2S8xl6Tw8HD16dNHQ4cO1axZs3T+/HmNHDlS991332WvxAIAAFcXj4ad3NxcDRo0SEeOHFFgYKDat2+vVatWqWfPnpKkf//733rsscd0xx13qLCwUC1bttTcuXMdHki6cOFCjRw5UrGxsfabCr7yyiue2iQAAFDNVLv77HiCs9fpAwCA6qPG3WcHAACgMhB2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AACAqRF2AADus2WL1L172RSoJgg7AAD3mTdPWrtWmj/f05UAdt6eLgAAUMMdOiQdPy5ZLNKSJWVtixdLiYmSYUghIVLTpp6tEVc1wg4A4Mo0a/bLzxZL2fTYMalTp1/aDaNKSwIuxGEsAMCVWbBA8v75387loaZ86u1d1g94ECM7AIArk5AghYc7juSUS0+XoqKqvibgAozsAADcx8vLcQpUA3wbAQBXLjRUstnKRndmzSqb2mxl7YCHcRgLAHDlGjeWDh6UfH3LTlIeNkw6d07y8/N0ZQBhBwDgJhcGG4uFoINqg8NYAADA1Dwadt544w21b99eVqtVVqtVMTExWrFihcM8aWlp6t69u+rUqSOr1arbbrtNZ86csfefOHFCCQkJslqtCgoKUlJSkgoLC6t6UwC4G48dAOAmHg07jRs31tSpU7V161Zt2bJF3bt3V//+/bVz505JZUGnT58+6tWrlzZv3qyMjAyNHDlSXhec5Z+QkKCdO3cqNTVVy5cv14YNGzRs2DBPbRIAd+GxAwDcxGIY1eu2lsHBwZo+fbqSkpJ08803q2fPnpo0adIl5921a5ciIiKUkZGh6OhoSdLKlSvVr18/ff/992rUqNElP1dUVKSioiL7+/z8fIWFhSkvL09Wq9X9GwXAORc+dqBvXyk3t+xqnhUreOwAgIvk5+crMDDwd/9+V5tzdkpKSrR48WKdOnVKMTExys3NVXp6ukJDQ9WlSxc1aNBAXbt21Zdffmn/TFpamoKCguxBR5J69OghLy8vpaenX3ZdU6ZMUWBgoP0VFhZWqdsGwEnNmknR0WWXLR87VtZW/tiB6GjHxxIAgJM8HnZ27NihgIAA+fn56aGHHtLHH3+siIgI/e9//5MkPfPMMxo6dKhWrlypqKgoxcbGau/evZKknJwchf7qHg7e3t4KDg5WTk7OZdeZkpKivLw8+ys7O7vyNhCA83jsAIBK4PFLz1u3bq3MzEzl5eXpgw8+UGJiotavX6/S0lJJ0vDhwzVkyBBJ0o033qjVq1fr3Xff1ZQpUyq8Tj8/P/lxSSRQ/fDYAQCVwONhx9fXVy1btpQkderUSRkZGZo5c6Yee+wxSVJERITD/OHh4crKypIk2Ww25ebmOvQXFxfrxIkTstlsVVA9gErj5SWVlv4yBYAK8vhhrF8rLS1VUVGRmjVrpkaNGmn37t0O/Xv27FHTn09QjImJ0cmTJ7V161Z7/5o1a1RaWqrOnTtXad0A3ITHDgBwM4+O7KSkpKhv375q0qSJCgoKtGjRIq1bt06rVq2SxWLR+PHj9fTTT6tDhw7q2LGj5s6dq++++04ffPCBpLJRnj59+mjo0KGaNWuWzp8/r5EjR+q+++677JVYAKo5HjsAwM08GnZyc3M1aNAgHTlyRIGBgWrfvr1WrVqlnj17SpLGjh2rs2fPaty4cTpx4oQ6dOig1NRUtWjRwr6MhQsXauTIkYqNjZWXl5fi4+P1yiuveGqTALgDjx0A4EbV7j47nuDsdfoAAKD6qHH32QEAAKgMhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqhB0AAGBqHg07b7zxhtq3by+r1Sqr1aqYmBitWLHiovkMw1Dfvn1lsVi0bNkyh76srCzFxcXJ399foaGhGj9+vIqLi6toCwAAQHXn7cmVN27cWFOnTlWrVq1kGIbmzp2r/v37a/v27Wrbtq19vhkzZshisVz0+ZKSEsXFxclms2nTpk06cuSIBg0aJB8fHz3//PNVuSkAAKCashiGYXi6iAsFBwdr+vTpSkpKkiRlZmbq9ttv15YtW9SwYUN9/PHHuvPOOyVJK1as0O23367Dhw+rQYMGkqRZs2ZpwoQJOnbsmHx9fZ1aZ35+vgIDA5WXlyer1Vop2wUAANzL2b/f1eacnZKSEi1evFinTp1STEyMJOn06dO6//779dprr8lms130mbS0NEVGRtqDjiT17t1b+fn52rlz52XXVVRUpPz8fIcXAAAwJ4+HnR07diggIEB+fn566KGH9PHHHysiIkKSNG7cOHXp0kX9+/e/5GdzcnIcgo4k+/ucnJzLrnPKlCkKDAy0v8LCwty0NQAAoLrx6Dk7ktS6dWtlZmYqLy9PH3zwgRITE7V+/Xrt27dPa9as0fbt292+zpSUFD388MP29/n5+QQeAABMyuNhx9fXVy1btpQkderUSRkZGZo5c6Zq166t/fv3KygoyGH++Ph43XrrrVq3bp1sNps2b97s0H/06FFJuuRhr3J+fn7y8/Nz74YAKLNli/T3v0vTpknR0Z6uBgA8fxjr10pLS1VUVKTHHntM33zzjTIzM+0vSXr55Zc1e/ZsSVJMTIx27Nih3Nxc++dTU1NltVrth8IAVLF586S1a6X58z1dCQBI8vDITkpKivr27asmTZqooKBAixYt0rp167Rq1SrZbLZLjs40adJE119/vSSpV69eioiI0AMPPKBp06YpJydHTzzxhJKTkxm5AarSoUPS8eOSxSItWVLWtnixlJgoGYYUEiI1berZGgFctTwadnJzczVo0CAdOXJEgYGBat++vVatWqWePXs69flatWpp+fLlGjFihGJiYlSnTh0lJiZq4sSJlVw5AAfNmv3yc/k9sY4dkzp1+qW9et3lAsBVpNrdZ8cTuM8OcIUWLpQGD5Yudfdyb29pzhwpIaGqqwJgcs7+/fb4CcoATCAhQQoPdxzJKZeeLkVFVX1NAPCzaneCMoAazsvLcQoAHsZvIwDuERoq2WxlozuzZpVNbbaydgDwIA5jAXCPxo2lgwclX9+yk5SHDZPOnZO4MhKAhxF2ALjPhcHGYiHoAKgWOIwFAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjbADAABMjcdFSDIMQ5KUn5/v4UoAAICzyv9ul/8dvxzCjqSCggJJUlhYmIcrAQAAriooKFBgYOBl+y3G78Whq0BpaakOHz6sunXrymKxXHKe/Px8hYWFKTs7W1artYorvPqwv6sO+7rqsK+rFvu76nhqXxuGoYKCAjVq1EheXpc/M4eRHUleXl5q3LixU/NarVb+p6lC7O+qw76uOuzrqsX+rjqe2Ne/NaJTjhOUAQCAqRF2AACAqRF2nOTn56enn35afn5+ni7lqsD+rjrs66rDvq5a7O+qU933NScoAwAAU2NkBwAAmBphBwAAmBphBwAAmBphBwAAmBph5wJTp06VxWLR2LFj7W3dunWTxWJxeD300EMOn8vKylJcXJz8/f0VGhqq8ePHq7i4uIqrr/6eeeaZi/ZlmzZt7P1nz55VcnKy6tWrp4CAAMXHx+vo0aMOy2BfO+f39jXfa/f64YcfNHDgQNWrV0+1a9dWZGSktmzZYu83DENPPfWUGjZsqNq1a6tHjx7au3evwzJOnDihhIQEWa1WBQUFKSkpSYWFhVW9KdXe7+3rwYMHX/Td7tOnj8My2NfOadas2UX70mKxKDk5WVLN+p3NHZR/lpGRoTfffFPt27e/qG/o0KGaOHGi/b2/v7/955KSEsXFxclms2nTpk06cuSIBg0aJB8fHz3//PNVUntN0rZtW33xxRf2997ev3wFx40bp88++0xLly5VYGCgRo4cqbvvvltfffWVJPa1q35rX0t8r93lp59+0i233KI//vGPWrFiherXr6+9e/fq2muvtc8zbdo0vfLKK5o7d66uv/56Pfnkk+rdu7f++9//6pprrpEkJSQk6MiRI0pNTdX58+c1ZMgQDRs2TIsWLfLUplU7zuxrSerTp49mz55tf//ry6HZ187JyMhQSUmJ/f23336rnj176i9/+YukGvY724BRUFBgtGrVykhNTTW6du1qjBkzxt736/e/9u9//9vw8vIycnJy7G1vvPGGYbVajaKiokqsuuZ5+umnjQ4dOlyy7+TJk4aPj4+xdOlSe9uuXbsMSUZaWpphGOxrV/zWvjYMvtfuNGHCBOP//u//LttfWlpq2Gw2Y/r06fa2kydPGn5+fsZ7771nGIZh/Pe//zUkGRkZGfZ5VqxYYVgsFuOHH36ovOJrmN/b14ZhGImJiUb//v0v28++rrgxY8YYLVq0MEpLS2vc72wOY0lKTk5WXFycevToccn+hQsXKiQkRO3atVNKSopOnz5t70tLS1NkZKQaNGhgb+vdu7fy8/O1c+fOSq+9ptm7d68aNWqk5s2bKyEhQVlZWZKkrVu36vz58w7/Ddq0aaMmTZooLS1NEvvaVZfb1+X4XrvHJ598oujoaP3lL39RaGiobrzxRr399tv2/gMHDignJ8fhux0YGKjOnTs7fLeDgoIUHR1tn6dHjx7y8vJSenp61W1MNfd7+7rcunXrFBoaqtatW2vEiBH68ccf7X3s64o5d+6cFixYoAcffFAWi6XG/c6+6g9jLV68WNu2bVNGRsYl+++//341bdpUjRo10jfffKMJEyZo9+7d+uijjyRJOTk5Dv8hJdnf5+TkVG7xNUznzp01Z84ctW7dWkeOHNGzzz6rW2+9Vd9++61ycnLk6+uroKAgh880aNDAvh/Z1877rX1dt25dvtdu9L///U9vvPGGHn74YT3++OPKyMjQ6NGj5evrq8TERPv+utT+vPC7HRoa6tDv7e2t4OBg9vcFfm9fS2WHsO6++25df/312r9/vx5//HH17dtXaWlpqlWrFvu6gpYtW6aTJ09q8ODBklTjfmdf1WEnOztbY8aMUWpqqv24+a8NGzbM/nNkZKQaNmyo2NhY7d+/Xy1atKiqUk2hb9++9p/bt2+vzp07q2nTpnr//fdVu3ZtD1ZmPr+1r5OSkvheu1Fpaamio6Pt5yDceOON+vbbbzVr1iz7H2C4hzP7+r777rPPHxkZqfbt26tFixZat26dYmNjPVK3Gbzzzjvq27evGjVq5OlSKuSqPoy1detW5ebmKioqSt7e3vL29tb69ev1yiuvyNvb2+HErHKdO3eWJO3bt0+SZLPZLjr7vPy9zWar5C2o2YKCgnTDDTdo3759stlsOnfunE6ePOkwz9GjR+37kX1dcRfu60vhe11xDRs2VEREhENbeHi4/bBh+f661P688Ludm5vr0F9cXKwTJ06wvy/we/v6Upo3b66QkBCH7zb72jWHDh3SF198ob/+9a/2tpr2O/uqDjuxsbHasWOHMjMz7a/o6GglJCQoMzNTtWrVuugzmZmZksr+p5OkmJgY7dixw+F/ntTUVFmt1ov+p4SjwsJC7d+/Xw0bNlSnTp3k4+Oj1atX2/t3796trKwsxcTESGJfX4kL9/Wl8L2uuFtuuUW7d+92aNuzZ4+aNm0qSbr++utls9kcvtv5+flKT093+G6fPHlSW7dutc+zZs0alZaW2oMofn9fX8r333+vH3/80eG7zb52zezZsxUaGqq4uDh7W437nV2lp0PXABdepbJv3z5j4sSJxpYtW4wDBw4Y//rXv4zmzZsbt912m33+4uJio127dkavXr2MzMxMY+XKlUb9+vWNlJQUD21B9fXII48Y69atMw4cOGB89dVXRo8ePYyQkBAjNzfXMAzDeOihh4wmTZoYa9asMbZs2WLExMQYMTEx9s+zr533W/ua77V7bd682fD29jYmT55s7N2711i4cKHh7+9vLFiwwD7P1KlTjaCgIONf//qX8c033xj9+/c3rr/+euPMmTP2efr06WPceOONRnp6uvHll18arVq1MgYMGOCJTaq2fm9fFxQUGI8++qiRlpZmHDhwwPjiiy+MqKgoo1WrVsbZs2fty2FfO6+kpMRo0qSJMWHChIv6atLvbMLOr1wYdrKysozbbrvNCA4ONvz8/IyWLVsa48ePN/Ly8hw+c/DgQaNv375G7dq1jZCQEOORRx4xzp8/74Hqq7d7773XaNiwoeHr62tcd911xr333mvs27fP3n/mzBnjb3/7m3Httdca/v7+xl133WUcOXLEYRnsa+f81r7me+1+n376qdGuXTvDz8/PaNOmjfHWW2859JeWlhpPPvmk0aBBA8PPz8+IjY01du/e7TDPjz/+aAwYMMAICAgwrFarMWTIEKOgoKAqN6NG+K19ffr0aaNXr15G/fr1DR8fH6Np06bG0KFDHS59Ngz2tStWrVplSLro+2oYNet3tsUwDKNqx5IAAACqzlV9zg4AADA/wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4AADA1wg4A07BYLFq2bFmlrqNbt24aO3Zspa4DgHsRdgC4LC0tTbVq1XJ4MKCzmjVrphkzZri/qN9xxx13qE+fPpfs27hxoywWi7755psqrgpAVSDsAHDZO++8o1GjRmnDhg06fPiwp8txSlJSklJTU/X9999f1Dd79mxFR0erffv2HqgMQGUj7ABwSWFhoZYsWaIRI0YoLi5Oc+bMuWieTz/9VH/4wx90zTXXKCQkRHfddZekskNAhw4d0rhx42SxWGSxWCRJzzzzjDp27OiwjBkzZqhZs2b29xkZGerZs6dCQkIUGBiorl27atu2bU7Xffvtt6t+/foX1VtYWKilS5cqKSlJP/74owYMGKDrrrtO/v7+ioyM1Hvvvfeby73UobOgoCCH9WRnZ+uee+5RUFCQgoOD1b9/fx08eNDev27dOt10002qU6eOgoKCdMstt+jQoUNObxuA30bYAeCS999/X23atFHr1q01cOBAvfvuu7rwecKfffaZ7rrrLvXr10/bt2/X6tWrddNNN0mSPvroIzVu3FgTJ07UkSNHdOTIEafXW1BQoMTERH355Zf6z3/+o1atWqlfv34qKChw6vPe3t4aNGiQ5syZ41Dv0qVLVVJSogEDBujs2bPq1KmTPvvsM3377bcaNmyYHnjgAW3evNnpOn/t/Pnz6t27t+rWrauNGzfqq6++UkBAgPr06aNz586puLhYd955p7p27apvvvlGaWlpGjZsmD0IArhy3p4uAEDN8s4772jgwIGSpD59+igvL0/r169Xt27dJEmTJ0/Wfffdp2effdb+mQ4dOkiSgoODVatWLdWtW1c2m82l9Xbv3t3h/VtvvaWgoCCtX79et99+u1PLePDBBzV9+nSHemfPnq34+HgFBgYqMDBQjz76qH3+UaNGadWqVXr//fftgc1VS5YsUWlpqf75z3/aA8zs2bMVFBSkdevWKTo6Wnl5ebr99tvVokULSVJ4eHiF1gXg0hjZAeC03bt3a/PmzRowYICkstGSe++9V++88459nszMTMXGxrp93UePHtXQoUPVqlUrBQYGymq1qrCwUFlZWU4vo02bNurSpYveffddSdK+ffu0ceNGJSUlSZJKSko0adIkRUZGKjg4WAEBAVq1apVL6/i1r7/+Wvv27VPdunUVEBCggIAABQcH6+zZs9q/f7+Cg4M1ePBg9e7dW3fccYdmzpzp0ogXgN/HyA4Ap73zzjsqLi5Wo0aN7G2GYcjPz0+vvvqqAgMDVbt2bZeX6+Xl5XBoSSo7/HOhxMRE/fjjj5o5c6aaNm0qPz8/xcTE6Ny5cy6tKykpSaNGjdJrr72m2bNnq0WLFurataskafr06Zo5c6ZmzJihyMhI1alTR2PHjv3NdVgslt+svbCwUJ06ddLChQsv+mz9+vUllY30jB49WitXrtSSJUv0xBNPKDU1VTfffLNL2wbg0hjZAeCU4uJizZs3Ty+99JIyMzPtr6+//lqNGjWyn8jbvn17rV69+rLL8fX1VUlJiUNb/fr1lZOT4xAaMjMzHeb56quvNHr0aPXr109t27aVn5+fjh8/7vJ23HPPPfLy8tKiRYs0b948Pfjgg/bDS1999ZX69++vgQMHqkOHDmrevLn27Nnzm8urX7++w0jM3r17dfr0afv7qKgo7d27V6GhoWrZsqXDKzAw0D7fjTfeqJSUFG3atEnt2rXTokWLXN42AJdG2AHglOXLl+unn35SUlKS2rVr5/CKj4+3H8p6+umn9d577+npp5/Wrl27tGPHDr3wwgv25TRr1kwbNmzQDz/8YA8r3bp107FjxzRt2jTt379fr732mlasWOGw/latWmn+/PnatWuX0tPTlZCQUKFRpICAAN17771KSUnRkSNHNHjwYId1pKamatOmTdq1a5eGDx+uo0eP/ubyunfvrldffVXbt2/Xli1b9NBDD8nHx8fen5CQoJCQEPXv318bN27UgQMHtG7dOo0ePVrff/+9Dhw4oJSUFKWlpenQoUP6/PPPtXfvXs7bAdyIsAPAKe+884569OjhMBpRLj4+Xlu2bNE333yjbt26aenSpfrkk0/UsWNHde/e3eFqpokTJ+rgwYNq0aKF/TBOeHi4Xn/9db322mvq0KGDNm/e7HCicPn6f/rpJ0VFRemBBx7Q6NGjFRoaWqFtSUpK0k8//aTevXs7HJJ74oknFBUVpd69e6tbt26y2Wy68847f3NZL730ksLCwnTrrbfq/vvv16OPPip/f397v7+/vzZs2KAmTZro7rvvVnh4uJKSknT27FlZrVb5+/vru+++U3x8vG644QYNGzZMycnJGj58eIW2DcDFLMavDzYDAACYCCM7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1Ag7AADA1P4/XIleGdWBIL0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#9 精度评价、模拟绘图制作与模型参数与精度保存\n",
    "\n",
    "#精度评价与模拟图像就不用过多说啦~\n",
    "#最后，我们最好将模型参数与精度计量指标结果保存在Excel表格中的这样子旁边借程序。\n",
    "#这里就不再一介介绍啦，大家对照片代码中的注解即可。\n",
    "\n",
    "#调用AccuracyVerification函数，进行精度验证指标的计算与绘图\n",
    "AccuracyResult=AccuracyVerification(PredictValues,TestY)\n",
    "PearsonR,R2,RMSE,PredictY=AccuracyResult[0],AccuracyResult[1],AccuracyResult[2],AccuracyResult[3]\n",
    "\n",
    "# 调用WriteAccuracy函数，将模型所涉及的参数与最终精度结果保存\n",
    "WriteAccuracy(MyResultSavePath,PearsonR,R2,RMSE,TestSize,RandomSeed,OptMethod,LearningRate,DecayStep,\n",
    "              DecayRate,','.join('%s' %i for i in HiddenLayer),ActFun,Dropout,LossReduction,\n",
    "              BatchNorm,TrainBatchSize,TrainStep,EvalBatchSize,PredictBatchSize)\n",
    "#遇到尺寸之类的报错，从头到尾运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47363985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cudaOCRpy37",
   "language": "python",
   "name": "cudaocrpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
